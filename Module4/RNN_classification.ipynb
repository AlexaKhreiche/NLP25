{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4f8637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93dc0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\suzan.awinat\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f22136c83a747bda53a92ca7b246472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edca95e5760a46bb98b12b743aaaf48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\suzan.awinat\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete0XFH56\\imdb_review…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\suzan.awinat\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete0XFH56\\imdb_review…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\suzan.awinat\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete0XFH56\\imdb_review…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to C:\\Users\\suzan.awinat\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Obtain the imdb review dataset from tensorflow datasets\n",
    "dataset = tfds.load('imdb_reviews', as_supervised=True)\n",
    "\n",
    "# Seperate test and train datasets\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "# Split the test and train data into batches of 32\n",
    "# and shuffling the training set\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(10000)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e621631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      " b\"Wow. This was probably the worst DCOM ever. I watched the first half hour and I laughed. Brenda Song plays Wendy, the popular girl with the hot jock boyfriend and stuck up friends who is determined to be Homecoming Queen. She is supposed to save the world as a warrior, and Shin comes to her aid to help her with her Martial Arts. Shin teaches her the skills of a snake, tiger, etc. and she has to learn certain techniques to save the world.<br /><br />This movie is great for kids who want to learn about Martial Arts and the Chinese culture but the acting and casting was horrible.<br /><br />Brenda Song is a comedic actress and I can't see her playing a serious role. It was laugh out loud funny watching her cry over Shin. Shin couldn't act at all, and everything was totally unbelievable.<br /><br />I watched this movie and tried to think of something similar, and the thing I came up with was the Power Rangers. This movie is so fake and the stunts were so Power Ranger-esquire that it was just corny and stupid. The characters weren't likable and I just couldn't stand to watch it. Disney really needs to take time to make some decent movies. High School Musical is the only movie that deserves to be on Disney Channel, along with other movies like Jumping Ship, Color of Friendship, Go Figure, Read It and Weep, & Stuck in the Suburbs.<br /><br />If you like action-adventure and corny jokes, you'll like this movie.\"\n",
      "\n",
      "Label:  0\n"
     ]
    }
   ],
   "source": [
    "#iter function to create an iterator for the training dataset and then extracts the first batch\n",
    "example, label = next(iter(train_dataset))\n",
    "print('Text:\\n', example.numpy()[0])\n",
    "print('\\nLabel: ', label.numpy()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ad5cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:  b\"Wow. This was probably the worst DCOM ever. I watched the first half hour and I laughed. Brenda Song plays Wendy, the popular girl with the hot jock boyfriend and stuck up friends who is determined to be Homecoming Queen. She is supposed to save the world as a warrior, and Shin comes to her aid to help her with her Martial Arts. Shin teaches her the skills of a snake, tiger, etc. and she has to learn certain techniques to save the world.<br /><br />This movie is great for kids who want to learn about Martial Arts and the Chinese culture but the acting and casting was horrible.<br /><br />Brenda Song is a comedic actress and I can't see her playing a serious role. It was laugh out loud funny watching her cry over Shin. Shin couldn't act at all, and everything was totally unbelievable.<br /><br />I watched this movie and tried to think of something similar, and the thing I came up with was the Power Rangers. This movie is so fake and the stunts were so Power Ranger-esquire that it was just corny and stupid. The characters weren't likable and I just couldn't stand to watch it. Disney really needs to take time to make some decent movies. High School Musical is the only movie that deserves to be on Disney Channel, along with other movies like Jumping Ship, Color of Friendship, Go Figure, Read It and Weep, & Stuck in the Suburbs.<br /><br />If you like action-adventure and corny jokes, you'll like this movie.\"\n",
      "encoded:  [1420   11   14  235    2  240    1  122   10  284    2   86  357  560\n",
      "    3   10 1434 4839  616  285 4886    2 1045  247   17    2  918 9551\n",
      " 1519    3 1524   58  340   37    7 2894    6   28    1 1600   55    7\n",
      "  402    6  574    2  188   15    4 3780    3    1  257    6   40 4353\n",
      "    6  328   40   17   40 1626 1694    1 5193   40    2 1910    5    4\n",
      " 4458 4987  572    3   55   44    6  821  772 3427    6  574    2 3646\n",
      "   13   11   18    7   85   16  327   37  178    6  821   43 1626 1694\n",
      "    3    2 1611 1226   19    2  112    3  957   14    1   13 4839  616\n",
      "    7    4 1661  512    3   10  175   68   40  380    4  605  214    9\n",
      "   14  475   46 1383  162  147   40 1381  126    1    1  404  504   31\n",
      "   32    3  279   14  467    1   13   10  284   11   18    3  775    6\n",
      "  103    5  140  712    3    2  151   10  366   58   17   14    2  669\n",
      " 4910   11   18    7   38 1205    3    2 3334   66   38  669    1   12\n",
      "    9   14   41 2006    3  375    2  102 1124 1414    3   10   41  404\n",
      "  847    6  104    9  905   63  716    6  189   62    6   94   47  528\n",
      "   93  322  400  619    7    2   61   18   12  985    6   28   21  905\n",
      " 1284  354   17   81   93   39 3575 1682 1371    5 1821  138  811  321\n",
      "    9    3    1 1524    8    2    1   13   45   23   39    1    3 2006\n",
      "  634  478   39   11   18]\n",
      "decoded:  wow this was probably the worst [UNK] ever i watched the first half hour and i laughed brenda song plays wendy the popular girl with the hot jock boyfriend and stuck up friends who is determined to be [UNK] queen she is supposed to save the world as a warrior and [UNK] comes to her aid to help her with her martial arts [UNK] teaches her the skills of a snake tiger etc and she has to learn certain techniques to save the worldbr br this movie is great for kids who want to learn about martial arts and the chinese culture but the acting and casting was [UNK] br brenda song is a comedic actress and i cant see her playing a serious role it was laugh out loud funny watching her cry over [UNK] [UNK] couldnt act at all and everything was totally [UNK] br i watched this movie and tried to think of something similar and the thing i came up with was the power rangers this movie is so fake and the stunts were so power [UNK] that it was just corny and stupid the characters werent likable and i just couldnt stand to watch it disney really needs to take time to make some decent movies high school musical is the only movie that deserves to be on disney channel along with other movies like jumping ship color of friendship go figure read it and [UNK] stuck in the [UNK] br if you like [UNK] and corny jokes youll like this movie\n"
     ]
    }
   ],
   "source": [
    "# Using the TextVectorization layer to normalize, split, and map strings\n",
    "# to integers.\n",
    "encoder = tf.keras.layers.TextVectorization(max_tokens=10000)\n",
    "encoder.adapt(train_dataset.map(lambda text, _: text))\n",
    "\n",
    "# Extracting the vocabulary from the TextVectorization layer.\n",
    "vocabulary = np.array(encoder.get_vocabulary())\n",
    "\n",
    "# Encoding a test example and decoding it back.\n",
    "original_text = example.numpy()[0]\n",
    "encoded_text = encoder(original_text).numpy()\n",
    "decoded_text = ' '.join(vocabulary[encoded_text])\n",
    "\n",
    "print('original: ', original_text)\n",
    "print('encoded: ', encoded_text)\n",
    "print('decoded: ', decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da47414f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVe  (None, None)              0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 64)          640000    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, None, 128)         66048     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 64)                41216     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 751489 (2.87 MB)\n",
      "Trainable params: 751489 (2.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "model = tf.keras.Sequential([\n",
    "\tencoder,\n",
    "\ttf.keras.layers.Embedding(\n",
    "\t\tlen(encoder.get_vocabulary()), 64, mask_zero=True),\n",
    "\ttf.keras.layers.Bidirectional(\n",
    "\t\ttf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "\ttf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "\ttf.keras.layers.Dense(64, activation='relu'),\n",
    "\ttf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "\tloss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "\toptimizer=tf.keras.optimizers.Adam(),\n",
    "\tmetrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c11e4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1443s 2s/step - loss: 0.4313 - accuracy: 0.7902 - val_loss: 0.3491 - val_accuracy: 0.8551\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 1588s 2s/step - loss: 0.2711 - accuracy: 0.8897 - val_loss: 0.3215 - val_accuracy: 0.8736\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 1887s 2s/step - loss: 0.1831 - accuracy: 0.9301 - val_loss: 0.3352 - val_accuracy: 0.8762\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 2256s 3s/step - loss: 0.1294 - accuracy: 0.9527 - val_loss: 0.3771 - val_accuracy: 0.8669\n",
      "Epoch 5/5\n",
      "156/782 [====>.........................] - ETA: 25:30 - loss: 0.0579 - accuracy: 0.9818"
     ]
    }
   ],
   "source": [
    "# Training the model and validating it on test set\n",
    "history = model.fit(\n",
    "\ttrain_dataset, \n",
    "\tepochs=5,\n",
    "\tvalidation_data=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the accuracy and loss over time\n",
    "\n",
    "# Training history\n",
    "history_dict = history.history\n",
    "\n",
    "# Seperating validation and training accuracy\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "# Seperating validation and training loss\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Accuracy', 'Validation Accuracy'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Loss', 'Validation Loss'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ebd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "sample_text = (\n",
    "\t'''The movie was so good and the animation are so dope. \n",
    "\tI would recommend my friends to watch it.'''\n",
    ")\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(*predictions[0])\n",
    "\n",
    "# Print the label based on the prediction\n",
    "if predictions[0] > 0:\n",
    "\tprint('The review is positive')\n",
    "else:\n",
    "\tprint('The review is negative')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
