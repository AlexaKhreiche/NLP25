{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "573de3f1",
      "metadata": {
        "id": "573de3f1"
      },
      "outputs": [],
      "source": [
        "# Small LSTM Network to Generate Text for Alice in Wonderland\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "78ec9ed2",
      "metadata": {
        "id": "78ec9ed2"
      },
      "outputs": [],
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nueva secci√≥n"
      ],
      "metadata": {
        "id": "kvu0quQ1Pi0r"
      },
      "id": "kvu0quQ1Pi0r"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "be3c20c4",
      "metadata": {
        "id": "be3c20c4"
      },
      "outputs": [],
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "576168dc",
      "metadata": {
        "id": "576168dc",
        "outputId": "131bf326-f8d3-4539-eede-074e1f78cfa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  163944\n",
            "Total Vocab:  65\n"
          ]
        }
      ],
      "source": [
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e19db6bc",
      "metadata": {
        "id": "e19db6bc",
        "outputId": "67335ca7-bbdf-4994-cc00-eb53b02e6e8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  163844\n"
          ]
        }
      ],
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6b66b7a7",
      "metadata": {
        "id": "6b66b7a7"
      },
      "outputs": [],
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "375c70b1",
      "metadata": {
        "id": "375c70b1"
      },
      "outputs": [],
      "source": [
        "# normalize\n",
        "X = X / float(n_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4d16bf97",
      "metadata": {
        "id": "4d16bf97"
      },
      "outputs": [],
      "source": [
        "# one hot encode the output variable\n",
        "y = to_categorical(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ce007d7a",
      "metadata": {
        "id": "ce007d7a",
        "outputId": "2f36e623-e85f-4417-9d17-2e3adad599e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5d15ab0a",
      "metadata": {
        "id": "5d15ab0a",
        "outputId": "46100775-d017-4596-b1a7-702bd9f56d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The filepath provided must end in `.keras` (Keras model format). Received: filepath=weights-improvement-{epoch:02d}-{loss:.4f}.hdf5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7e6a5ad35bf8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# define the checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             ):\n\u001b[0;32m--> 194\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    195\u001b[0m                     \u001b[0;34m\"The filepath provided must end in `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                     \u001b[0;34m\"(Keras model format). Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The filepath provided must end in `.keras` (Keras model format). Received: filepath=weights-improvement-{epoch:02d}-{loss:.4f}.hdf5"
          ]
        }
      ],
      "source": [
        "# define the checkpoint\n",
        "#filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "#checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "#callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.keras\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "szRu3xhJRVyD"
      },
      "id": "szRu3xhJRVyD",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f2214a1",
      "metadata": {
        "id": "8f2214a1",
        "outputId": "a57eb025-bbaa-41a0-cbf5-090a52999313",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m 270/1281\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m10:40\u001b[0m 634ms/step - loss: 3.2533"
          ]
        }
      ],
      "source": [
        "# fit the model\n",
        "model.fit(X, y, epochs=10, batch_size=128, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9085b582",
      "metadata": {
        "id": "9085b582"
      },
      "outputs": [],
      "source": [
        "#import sys\n",
        "# load the network weights\n",
        "#filename = \"weights-improvement-20-2.1411.hdf5\"\n",
        "#model.load_weights(filename)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# load the network weights\n",
        "filename = \"weights-improvement-20-2.1411.keras\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "hXpMEvNERvVo"
      },
      "id": "hXpMEvNERvVo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5cc56c",
      "metadata": {
        "id": "9f5cc56c"
      },
      "outputs": [],
      "source": [
        "# pick a random seed\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([chr(value) for value in pattern]), \"\\\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "885ff3ec",
      "metadata": {
        "id": "885ff3ec"
      },
      "outputs": [],
      "source": [
        "# generate characters\n",
        "for i in range(1000):\n",
        " x = np.reshape(pattern, (1, len(pattern), 1))\n",
        " x = x / float(n_vocab)\n",
        " prediction = model.predict(x, verbose=0)\n",
        " index = np.argmax(prediction)\n",
        " result = int_to_char[index]\n",
        " seq_in = [chr(value) for value in pattern]\n",
        " sys.stdout.write(result)\n",
        " pattern.append(index)\n",
        " pattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gpu2",
      "language": "python",
      "name": "gpu2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}