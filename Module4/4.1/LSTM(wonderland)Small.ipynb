{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573de3f1",
   "metadata": {
    "id": "573de3f1"
   },
   "outputs": [],
   "source": [
    "# Small LSTM Network to Generate Text for Alice in Wonderland\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ec9ed2",
   "metadata": {
    "id": "78ec9ed2"
   },
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"wonderland.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3c20c4",
   "metadata": {
    "id": "be3c20c4"
   },
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "576168dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "576168dc",
    "outputId": "131bf326-f8d3-4539-eede-074e1f78cfa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  163943\n",
      "Total Vocab:  64\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e19db6bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e19db6bc",
    "outputId": "67335ca7-bbdf-4994-cc00-eb53b02e6e8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  163843\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b66b7a7",
   "metadata": {
    "id": "6b66b7a7"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "375c70b1",
   "metadata": {
    "id": "375c70b1"
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "X = X / float(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d16bf97",
   "metadata": {
    "id": "4d16bf97"
   },
   "outputs": [],
   "source": [
    "# one hot encode the output variable\n",
    "y = to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce007d7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce007d7a",
    "outputId": "2f36e623-e85f-4417-9d17-2e3adad599e2"
   },
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d15ab0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "5d15ab0a",
    "outputId": "46100775-d017-4596-b1a7-702bd9f56d25"
   },
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "#filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "#callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "szRu3xhJRVyD",
   "metadata": {
    "id": "szRu3xhJRVyD"
   },
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.keras\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f2214a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f2214a1",
    "outputId": "a57eb025-bbaa-41a0-cbf5-090a52999313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1281/1281 [==============================] - ETA: 0s - loss: 3.0127\n",
      "Epoch 1: loss improved from inf to 3.01274, saving model to weights-improvement-01-3.0127.keras\n",
      "1281/1281 [==============================] - 875s 674ms/step - loss: 3.0127\n",
      "Epoch 2/10\n",
      "1281/1281 [==============================] - ETA: 0s - loss: 2.8367\n",
      "Epoch 2: loss improved from 3.01274 to 2.83672, saving model to weights-improvement-02-2.8367.keras\n",
      "1281/1281 [==============================] - 886s 692ms/step - loss: 2.8367\n",
      "Epoch 3/10\n",
      "1281/1281 [==============================] - ETA: 0s - loss: 2.7550\n",
      "Epoch 3: loss improved from 2.83672 to 2.75499, saving model to weights-improvement-03-2.7550.keras\n",
      "1281/1281 [==============================] - 798s 623ms/step - loss: 2.7550\n",
      "Epoch 4/10\n",
      "1281/1281 [==============================] - ETA: 0s - loss: 2.6910\n",
      "Epoch 4: loss improved from 2.75499 to 2.69105, saving model to weights-improvement-04-2.6910.keras\n",
      "1281/1281 [==============================] - 905s 706ms/step - loss: 2.6910\n",
      "Epoch 5/10\n",
      "1281/1281 [==============================] - ETA: 0s - loss: 2.6381\n",
      "Epoch 5: loss improved from 2.69105 to 2.63814, saving model to weights-improvement-05-2.6381.keras\n",
      "1281/1281 [==============================] - 1466s 1s/step - loss: 2.6381\n",
      "Epoch 6/10\n",
      "1281/1281 [==============================] - ETA: 0s - loss: 2.5831\n",
      "Epoch 6: loss improved from 2.63814 to 2.58314, saving model to weights-improvement-06-2.5831.keras\n",
      "1281/1281 [==============================] - 1454s 1s/step - loss: 2.5831\n",
      "Epoch 7/10\n",
      "1281/1281 [==============================] - ETA: 0s - loss: 2.5335\n",
      "Epoch 7: loss improved from 2.58314 to 2.53347, saving model to weights-improvement-07-2.5335.keras\n",
      "1281/1281 [==============================] - 1620s 1s/step - loss: 2.5335\n",
      "Epoch 8/10\n",
      "1281/1281 [==============================] - ETA: 0s - loss: 2.4852\n",
      "Epoch 8: loss improved from 2.53347 to 2.48518, saving model to weights-improvement-08-2.4852.keras\n",
      "1281/1281 [==============================] - 1189s 928ms/step - loss: 2.4852\n",
      "Epoch 9/10\n",
      "1281/1281 [==============================] - ETA: 0s - loss: 2.4441\n",
      "Epoch 9: loss improved from 2.48518 to 2.44406, saving model to weights-improvement-09-2.4441.keras\n",
      "1281/1281 [==============================] - 1688s 1s/step - loss: 2.4441\n",
      "Epoch 10/10\n",
      "1281/1281 [==============================] - ETA: 0s - loss: 2.4076\n",
      "Epoch 10: loss improved from 2.44406 to 2.40759, saving model to weights-improvement-10-2.4076.keras\n",
      "1281/1281 [==============================] - 678s 529ms/step - loss: 2.4076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb27235120>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X, y, epochs=10, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9085b582",
   "metadata": {
    "id": "9085b582"
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "# load the network weights\n",
    "#filename = \"weights-improvement-20-2.1411.hdf5\"\n",
    "#model.load_weights(filename)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hXpMEvNERvVo",
   "metadata": {
    "id": "hXpMEvNERvVo"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# load the network weights\n",
    "filename = \"weights-improvement-10-2.4076.keras\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f5cc56c",
   "metadata": {
    "id": "9f5cc56c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" /\u0001#\"\")&+$\u0000\u001e",
      "\u0001)&11)\"\u0001!&##\"/\"+1\f",
      "\u0001\u001f21\u0001&#\u0001&;*\u0001+,1\u00011%\"\u00010\u001e",
      "*\"\n",
      "\u00011%\"\u0001+\"51\u0001.2\"01&,+\u0001&0\n",
      "\u00014%,\u0000&+\u00011%\"\u00014,/)!\u0001\u001e",
      "*\u0001&\u001a\u0001 \"\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([chr(value) for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "885ff3ec",
   "metadata": {
    "id": "885ff3ec"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'int_to_char' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prediction)\n\u001b[1;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mint_to_char\u001b[49m[index]\n\u001b[0;32m      8\u001b[0m seq_in \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mchr\u001b[39m(value) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m pattern]\n\u001b[0;32m      9\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(result)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'int_to_char' is not defined"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    " x = np.reshape(pattern, (1, len(pattern), 1))\n",
    " x = x / float(n_vocab)\n",
    " prediction = model.predict(x, verbose=0)\n",
    " index = np.argmax(prediction)\n",
    " result = int_to_char[index]\n",
    " seq_in = [chr(value) for value in pattern]\n",
    " sys.stdout.write(result)\n",
    " pattern.append(index)\n",
    " pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa50366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
